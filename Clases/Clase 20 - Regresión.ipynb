{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Regresion.ipynb","provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyPK3f8b97IEUVYKF1HMrohz"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","metadata":{"id":"v2Q9ELx_P1Eg"},"source":["# Regresión\n","\n","Vamos a trabajar con un dataset sobre precios de casas en boston:\n","\n","- CRIM per capita crime rate by town\n","- ZN proportion of residential land zoned for lots over 25,000 sq.ft.\n","- INDUS proportion of non-retail business acres per town\n","- CHAS Charles River dummy variable (= 1 if tract bounds river; 0 otherwise)\n","- NOX nitric oxides concentration (parts per 10 million)\n","- RM average number of rooms per dwelling\n","- AGE proportion of owner-occupied units built prior to 1940\n","- DIS weighted distances to five Boston employment centres\n","- RAD index of accessibility to radial highways\n","- TAX full-value property-tax rate per \\$10,000\n","- PTRATIO pupil-teacher ratio by town\n","- B: 1000(Bk - 0.63)^2 where Bk is the proportion of black people by town\n","- LSTAT % lower status of the population\n","- MEDV Median value of owner-occupied homes in $1000’s"]},{"cell_type":"code","metadata":{"id":"dCe-aKFQPiDm"},"source":["from sklearn.datasets import load_boston\n","import pandas as pd\n","import numpy as np\n","import matplotlib.pyplot as plt\n","import seaborn as sns"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":204},"id":"clVIq_UAQR1u","executionInfo":{"status":"ok","timestamp":1631827305426,"user_tz":180,"elapsed":406,"user":{"displayName":"Federico Baiocco","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ghf2wyATB48QBNVeVnR-1Y2rw_O5uZLAvphY2Otz9c=s64","userId":"14260194928165318342"}},"outputId":"ebdee121-babf-4434-8084-1c4f3433df85"},"source":["boston_data = load_boston()\n","df = pd.DataFrame(boston_data.data, columns=boston_data.feature_names)\n","df['target'] = pd.Series(boston_data.target)\n","df.head()"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>CRIM</th>\n","      <th>ZN</th>\n","      <th>INDUS</th>\n","      <th>CHAS</th>\n","      <th>NOX</th>\n","      <th>RM</th>\n","      <th>AGE</th>\n","      <th>DIS</th>\n","      <th>RAD</th>\n","      <th>TAX</th>\n","      <th>PTRATIO</th>\n","      <th>B</th>\n","      <th>LSTAT</th>\n","      <th>target</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>0.00632</td>\n","      <td>18.0</td>\n","      <td>2.31</td>\n","      <td>0.0</td>\n","      <td>0.538</td>\n","      <td>6.575</td>\n","      <td>65.2</td>\n","      <td>4.0900</td>\n","      <td>1.0</td>\n","      <td>296.0</td>\n","      <td>15.3</td>\n","      <td>396.90</td>\n","      <td>4.98</td>\n","      <td>24.0</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>0.02731</td>\n","      <td>0.0</td>\n","      <td>7.07</td>\n","      <td>0.0</td>\n","      <td>0.469</td>\n","      <td>6.421</td>\n","      <td>78.9</td>\n","      <td>4.9671</td>\n","      <td>2.0</td>\n","      <td>242.0</td>\n","      <td>17.8</td>\n","      <td>396.90</td>\n","      <td>9.14</td>\n","      <td>21.6</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>0.02729</td>\n","      <td>0.0</td>\n","      <td>7.07</td>\n","      <td>0.0</td>\n","      <td>0.469</td>\n","      <td>7.185</td>\n","      <td>61.1</td>\n","      <td>4.9671</td>\n","      <td>2.0</td>\n","      <td>242.0</td>\n","      <td>17.8</td>\n","      <td>392.83</td>\n","      <td>4.03</td>\n","      <td>34.7</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>0.03237</td>\n","      <td>0.0</td>\n","      <td>2.18</td>\n","      <td>0.0</td>\n","      <td>0.458</td>\n","      <td>6.998</td>\n","      <td>45.8</td>\n","      <td>6.0622</td>\n","      <td>3.0</td>\n","      <td>222.0</td>\n","      <td>18.7</td>\n","      <td>394.63</td>\n","      <td>2.94</td>\n","      <td>33.4</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>0.06905</td>\n","      <td>0.0</td>\n","      <td>2.18</td>\n","      <td>0.0</td>\n","      <td>0.458</td>\n","      <td>7.147</td>\n","      <td>54.2</td>\n","      <td>6.0622</td>\n","      <td>3.0</td>\n","      <td>222.0</td>\n","      <td>18.7</td>\n","      <td>396.90</td>\n","      <td>5.33</td>\n","      <td>36.2</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["      CRIM    ZN  INDUS  CHAS    NOX  ...    TAX  PTRATIO       B  LSTAT  target\n","0  0.00632  18.0   2.31   0.0  0.538  ...  296.0     15.3  396.90   4.98    24.0\n","1  0.02731   0.0   7.07   0.0  0.469  ...  242.0     17.8  396.90   9.14    21.6\n","2  0.02729   0.0   7.07   0.0  0.469  ...  242.0     17.8  392.83   4.03    34.7\n","3  0.03237   0.0   2.18   0.0  0.458  ...  222.0     18.7  394.63   2.94    33.4\n","4  0.06905   0.0   2.18   0.0  0.458  ...  222.0     18.7  396.90   5.33    36.2\n","\n","[5 rows x 14 columns]"]},"metadata":{},"execution_count":162}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"SJk-Mo19VDEf","executionInfo":{"status":"ok","timestamp":1631827305426,"user_tz":180,"elapsed":13,"user":{"displayName":"Federico Baiocco","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ghf2wyATB48QBNVeVnR-1Y2rw_O5uZLAvphY2Otz9c=s64","userId":"14260194928165318342"}},"outputId":"e35e5267-e958-4c43-c8b9-83ed4a27af9d"},"source":["df.shape"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(506, 14)"]},"metadata":{},"execution_count":163}]},{"cell_type":"markdown","metadata":{"id":"NcfGz6R5SOZS"},"source":["¿ Hay nulos ?"]},{"cell_type":"code","metadata":{"id":"I7atPz5JQS_i","executionInfo":{"status":"ok","timestamp":1631827406437,"user_tz":180,"elapsed":6,"user":{"displayName":"Federico Baiocco","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ghf2wyATB48QBNVeVnR-1Y2rw_O5uZLAvphY2Otz9c=s64","userId":"14260194928165318342"}}},"source":["# COMPLETAR"],"execution_count":1,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"dO04NHj8STlg"},"source":["Imprimir descripción del dataset:"]},{"cell_type":"code","metadata":{"id":"qRE9EvSqSQ_N","executionInfo":{"status":"ok","timestamp":1631827406437,"user_tz":180,"elapsed":5,"user":{"displayName":"Federico Baiocco","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ghf2wyATB48QBNVeVnR-1Y2rw_O5uZLAvphY2Otz9c=s64","userId":"14260194928165318342"}}},"source":["# COMPLETAR"],"execution_count":2,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"d9u49uIGSbAc"},"source":["¿ Hay variables correlacionadas entre sí ?"]},{"cell_type":"code","metadata":{"id":"h44LfhlpSXlC","executionInfo":{"status":"ok","timestamp":1631827406438,"user_tz":180,"elapsed":5,"user":{"displayName":"Federico Baiocco","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ghf2wyATB48QBNVeVnR-1Y2rw_O5uZLAvphY2Otz9c=s64","userId":"14260194928165318342"}}},"source":["# COMPLETAR"],"execution_count":3,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"V-qxnHCjSrwU"},"source":["En OLS no es bueno poner variables que esten correlacionadas entre sí.\n","\n","Por lo tanto, descartemos las variables que tienen una alta correlación (más de 0.9) y nos quedemos con 1 sola de ellas:"]},{"cell_type":"code","metadata":{"id":"k0eWosfrSjyh","executionInfo":{"status":"ok","timestamp":1631827409709,"user_tz":180,"elapsed":412,"user":{"displayName":"Federico Baiocco","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ghf2wyATB48QBNVeVnR-1Y2rw_O5uZLAvphY2Otz9c=s64","userId":"14260194928165318342"}}},"source":["# COMPLETAR"],"execution_count":4,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"pkZakrBBTMxm"},"source":["¿ Cómo se distribuye nuestro target ?"]},{"cell_type":"code","metadata":{"id":"QoMKsgliTPL8","executionInfo":{"status":"ok","timestamp":1631827412764,"user_tz":180,"elapsed":390,"user":{"displayName":"Federico Baiocco","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ghf2wyATB48QBNVeVnR-1Y2rw_O5uZLAvphY2Otz9c=s64","userId":"14260194928165318342"}}},"source":["# COMPLETAR"],"execution_count":5,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"yRQS1SkgU2Ru"},"source":["# Train - Test split"]},{"cell_type":"markdown","metadata":{"id":"bN50_GJzTG8L"},"source":["Ahora, vamos a comenzar entrenando un modelo de regresión lineal de sklearn. Primero que nada, separemos en train - test.\n","\n","Dejemos un 20% de los datos reservados para test y un random_state=42 para obtener todos los mismos resultados:"]},{"cell_type":"code","metadata":{"id":"prg-XfOCU3wG","executionInfo":{"status":"ok","timestamp":1631827414910,"user_tz":180,"elapsed":382,"user":{"displayName":"Federico Baiocco","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ghf2wyATB48QBNVeVnR-1Y2rw_O5uZLAvphY2Otz9c=s64","userId":"14260194928165318342"}}},"source":["# COMPLETAR"],"execution_count":6,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"zqtKKRmAUxCw"},"source":["# Linear regression\n","\n","Comenzaremos implementando una regresión lineal simple, utilizando Sklearn: https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LinearRegression.html\n","\n","En principio seleccionemos 1 sola variable como feature (puede ser por ejemplo, la que tenía la correlación más fuerte con el target)"]},{"cell_type":"code","metadata":{"id":"Z2nuQzEWVfJ-","executionInfo":{"status":"ok","timestamp":1631827419234,"user_tz":180,"elapsed":406,"user":{"displayName":"Federico Baiocco","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ghf2wyATB48QBNVeVnR-1Y2rw_O5uZLAvphY2Otz9c=s64","userId":"14260194928165318342"}}},"source":["# COMPLETAR"],"execution_count":7,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"qJAngcbHVnZu"},"source":["Importamos LinearRegression"]},{"cell_type":"code","metadata":{"id":"QYqesNp9TFma","executionInfo":{"status":"ok","timestamp":1631827421611,"user_tz":180,"elapsed":3,"user":{"displayName":"Federico Baiocco","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ghf2wyATB48QBNVeVnR-1Y2rw_O5uZLAvphY2Otz9c=s64","userId":"14260194928165318342"}}},"source":["# COMPLETAR"],"execution_count":8,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"zkYyMPGZVrkU"},"source":["Entrenamos el modelo:"]},{"cell_type":"code","metadata":{"id":"ZJDkGCgNVq0j"},"source":["# COMPLETAR"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"GR-FG0gFVxW2"},"source":["Y validamos su score en train y en test (si se fijan en la documentación, el LinearRegression ya trae un método para calcular el score)"]},{"cell_type":"code","metadata":{"id":"luU1qqkkVvoN","executionInfo":{"status":"ok","timestamp":1631827426163,"user_tz":180,"elapsed":377,"user":{"displayName":"Federico Baiocco","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ghf2wyATB48QBNVeVnR-1Y2rw_O5uZLAvphY2Otz9c=s64","userId":"14260194928165318342"}}},"source":["# COMPLETAR"],"execution_count":9,"outputs":[]},{"cell_type":"code","metadata":{"id":"spV2g-2qV3jQ","executionInfo":{"status":"ok","timestamp":1631827427539,"user_tz":180,"elapsed":2,"user":{"displayName":"Federico Baiocco","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ghf2wyATB48QBNVeVnR-1Y2rw_O5uZLAvphY2Otz9c=s64","userId":"14260194928165318342"}}},"source":["# COMPLETAR"],"execution_count":10,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"dHHx7pvlaHs1"},"source":["Al trabajar con una única feature, podemos graficar.\n","\n","Graficar un scatterplot que contenga:\n","- Puntos para los datos de entrenamiento (X_test, y_test)\n","- Puntos para los datos de test en otro color (Usar hue)\n","- Una linea con la regresión (predicciones que genera nuestro modelo) en train\n","- Misma linea pero para test\n","\n","Para esto, van a necesitar guardar las predicciones (su \"y_test_pred\" y \"y_train_pred\") en 2 listas:"]},{"cell_type":"code","metadata":{"id":"PnKdJuCfbKH0","executionInfo":{"status":"ok","timestamp":1631827432709,"user_tz":180,"elapsed":367,"user":{"displayName":"Federico Baiocco","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ghf2wyATB48QBNVeVnR-1Y2rw_O5uZLAvphY2Otz9c=s64","userId":"14260194928165318342"}}},"source":["# COMPLETAR"],"execution_count":12,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"ckAI1xzhXLkV"},"source":["Ahora, agreguemos una feature más al modelo y hagamos lo mismo:"]},{"cell_type":"code","metadata":{"id":"taXQTSTHV5H0","executionInfo":{"status":"ok","timestamp":1631827435398,"user_tz":180,"elapsed":379,"user":{"displayName":"Federico Baiocco","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ghf2wyATB48QBNVeVnR-1Y2rw_O5uZLAvphY2Otz9c=s64","userId":"14260194928165318342"}}},"source":["# COMPLETAR"],"execution_count":13,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"dOw-4uF2XZCQ"},"source":["Vemos que ya empieza a haber una diferencia significativa en los scores entre train y test. Por último, agreguemos todas las features y midamos los R squared:"]},{"cell_type":"code","metadata":{"id":"l9SiUqTUXYLa","executionInfo":{"status":"ok","timestamp":1631827454902,"user_tz":180,"elapsed":366,"user":{"displayName":"Federico Baiocco","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ghf2wyATB48QBNVeVnR-1Y2rw_O5uZLAvphY2Otz9c=s64","userId":"14260194928165318342"}}},"source":["# COMPLETAR"],"execution_count":16,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"QnfbxzZdXofm"},"source":["Vemos que nuestro modelo se ajusta bastante mejor a los datos de train que de test. \n","\n","Si vemos en la documentación, hay 2 atributos que nos pueden interesar:\n","\n","- coef_\n","- intercept_\n","\n","¿ Qué significan cada uno ?\n","\n","Imprimirlos"]},{"cell_type":"code","metadata":{"id":"QGZ531snXlZN","executionInfo":{"status":"ok","timestamp":1631827462140,"user_tz":180,"elapsed":409,"user":{"displayName":"Federico Baiocco","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ghf2wyATB48QBNVeVnR-1Y2rw_O5uZLAvphY2Otz9c=s64","userId":"14260194928165318342"}}},"source":["# COMPLETAR"],"execution_count":17,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"_KzB6j0Labq-"},"source":["Medir el mean squared error (Sklearn tiene la implementacion)"]},{"cell_type":"code","metadata":{"id":"87MMPHKvaFN_","executionInfo":{"status":"ok","timestamp":1631827466309,"user_tz":180,"elapsed":378,"user":{"displayName":"Federico Baiocco","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ghf2wyATB48QBNVeVnR-1Y2rw_O5uZLAvphY2Otz9c=s64","userId":"14260194928165318342"}}},"source":["# COMPLETAR"],"execution_count":18,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"M5rgsuI6b5t0"},"source":["# Árboles de decision\n","\n","Ahora, vamos a tratar de hacer lo mismo pero utilizando árboles de decision.\n","\n","Vimos que sklearn tiene una implementación para esto: https://scikit-learn.org/stable/modules/generated/sklearn.tree.DecisionTreeRegressor.html\n","\n","Importar el decision tree regressor:"]},{"cell_type":"code","metadata":{"id":"wWSaS6dEahpn","executionInfo":{"status":"ok","timestamp":1631827470895,"user_tz":180,"elapsed":368,"user":{"displayName":"Federico Baiocco","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ghf2wyATB48QBNVeVnR-1Y2rw_O5uZLAvphY2Otz9c=s64","userId":"14260194928165318342"}}},"source":["# COMPLETAR"],"execution_count":19,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"sE-sRi9CcKhE"},"source":["Vamos a hacer lo mismo que la clase pasada: Armar un listado de max_depths, entrenarlo y generar predicciones para cada elemento de la lista y decidir cuál es el mejor valor para max_depth.\n","\n","En este caso, en lugar de medir el fscore, mediremos el MSE (mean squared error) para comparar con los resultados obtenidos en la regresión lineal"]},{"cell_type":"code","metadata":{"id":"h5he8LHWcI4i","executionInfo":{"status":"ok","timestamp":1631827473198,"user_tz":180,"elapsed":409,"user":{"displayName":"Federico Baiocco","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ghf2wyATB48QBNVeVnR-1Y2rw_O5uZLAvphY2Otz9c=s64","userId":"14260194928165318342"}}},"source":["# COMPLETAR"],"execution_count":20,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Pga5I1yDdLb0"},"source":["Vemos como el error va disminuyendo a medida que aumenta el max depth, pero a partir de la profundidad 5, se separan ambas lineas (comienza a overfittear) por lo que avanzaremos con un max_depth=5.\n","\n","Entrenar el árbol con max_depth=5 y medir el mean_squared_error:"]},{"cell_type":"code","metadata":{"id":"2pJMYmEYdJcy","executionInfo":{"status":"ok","timestamp":1631827477400,"user_tz":180,"elapsed":558,"user":{"displayName":"Federico Baiocco","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ghf2wyATB48QBNVeVnR-1Y2rw_O5uZLAvphY2Otz9c=s64","userId":"14260194928165318342"}}},"source":["# COMPLETAR"],"execution_count":21,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"vkKrXdxCdlfn"},"source":["Vemos como podemos obtener mucho mejores resultados con un simple árbol de decisión.\n","\n","# KNN\n","\n","Ahora, probemos KNN.\n","\n","Vimos que KNN se puede utilizar para regresión y lo que hace es tomar una media ponderada de los vecinos más cercanos.\n","\n","Importemos knn regressor de sklearn:"]},{"cell_type":"code","metadata":{"id":"08HmuWChdjXk","executionInfo":{"status":"ok","timestamp":1631827483032,"user_tz":180,"elapsed":401,"user":{"displayName":"Federico Baiocco","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ghf2wyATB48QBNVeVnR-1Y2rw_O5uZLAvphY2Otz9c=s64","userId":"14260194928165318342"}}},"source":["# COMPLETAR"],"execution_count":22,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"TNPl61nAezB-"},"source":["Recuerden que en KNN, es importante escalar los datos. Por lo tanto, vamos a escalar X_train y X_test con un standard scaler.\n","\n","Escalar los datos:"]},{"cell_type":"code","metadata":{"id":"L7XhXI3ye4nO","executionInfo":{"status":"ok","timestamp":1631827485188,"user_tz":180,"elapsed":443,"user":{"displayName":"Federico Baiocco","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ghf2wyATB48QBNVeVnR-1Y2rw_O5uZLAvphY2Otz9c=s64","userId":"14260194928165318342"}}},"source":["# COMPLETAR"],"execution_count":23,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"EqWrzHLLd76S"},"source":["Ahora, vamos a entrenar el modelo con distintos valores de K, al igual que hicimos con la profundidad de los arboles.\n","\n","Entrenar knn con k desde 1 hasta 20 y decidir cuál es el mejor valor:"]},{"cell_type":"code","metadata":{"id":"cy9qjaGxd7Ra","executionInfo":{"status":"ok","timestamp":1631827488253,"user_tz":180,"elapsed":466,"user":{"displayName":"Federico Baiocco","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ghf2wyATB48QBNVeVnR-1Y2rw_O5uZLAvphY2Otz9c=s64","userId":"14260194928165318342"}}},"source":["# COMPLETAR\n"],"execution_count":24,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"D-rzQoBWeVwH"},"source":["Observando el gráfico, decidir el mejor valor de K y volver a entrenar knn.\n","\n","Luego, medir el MSE y comparar con los modelos anteriores:"]},{"cell_type":"code","metadata":{"id":"KZfPp3iWeO9Z","executionInfo":{"status":"ok","timestamp":1631827494995,"user_tz":180,"elapsed":433,"user":{"displayName":"Federico Baiocco","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ghf2wyATB48QBNVeVnR-1Y2rw_O5uZLAvphY2Otz9c=s64","userId":"14260194928165318342"}}},"source":["# COMPLETAR"],"execution_count":25,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Vr6r_xjZesqb"},"source":["¿ Conclusiones ?"]}]}